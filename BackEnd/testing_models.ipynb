{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skill: html low demand level\n",
      "Skill: css low demand level\n",
      "Skill: javascript low demand level\n",
      "Skill: react low demand level\n",
      "Skill: angular low demand level\n",
      "Skill: python low demand level\n",
      "Skill: data analysis low demand level\n",
      "Skill: machine learning low demand level\n",
      "Skill: project management low demand level\n",
      "Skill: database low demand level\n",
      "Skill: sql low demand level\n",
      "Skill: nosql high demand level\n",
      "Skill: web development low demand level\n",
      "Skill: front-end middle demand level\n",
      "Skill: back-end low demand level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class Kmeans:\n",
    "    '''Implementing Kmeans algorithm.'''\n",
    "\n",
    "    def __init__(self, n_clusters, max_iter=100, random_state=123):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def initializ_centroids(self, X):\n",
    "        np.random.RandomState(self.random_state)\n",
    "        random_idx = np.random.permutation(len(X))\n",
    "        centroids = X[random_idx[:self.n_clusters]]\n",
    "        return centroids\n",
    "\n",
    "    def compute_centroids(self, X, labels):\n",
    "        centroids = np.zeros((self.n_clusters, len(X[0])))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels == k, :], axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def compute_distance(self, X, centroids):\n",
    "        distance = np.zeros((len(X), self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            row_norm = norm(X - centroids[k, :], axis=1)\n",
    "            distance[:, k] = np.square(row_norm)\n",
    "        return distance\n",
    "\n",
    "    def find_closest_cluster(self, distance):\n",
    "        return np.argmin(distance, axis=1)\n",
    "\n",
    "    def compute_sse(self, X, labels, centroids):\n",
    "        distance = np.zeros(len(X))\n",
    "        for k in range(self.n_clusters):\n",
    "            distance[labels == k] = norm(X[labels == k] - centroids[k], axis=1)\n",
    "        return np.sum(np.square(distance))\n",
    "\n",
    "    def fit(self, skills):\n",
    "        skill_to_index = {skill: i for i, skill in enumerate(skills)}\n",
    "        X = np.eye(len(skills))\n",
    "        self.centroids = self.initializ_centroids(X)\n",
    "        for i in range(self.max_iter):\n",
    "            old_centroids = self.centroids\n",
    "            distance = self.compute_distance(X, old_centroids)\n",
    "            self.labels = self.find_closest_cluster(distance)\n",
    "            self.centroids = self.compute_centroids(X, self.labels)\n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "        self.error = self.compute_sse(X, self.labels, self.centroids)\n",
    "\n",
    "    def predict(self, skills):\n",
    "        skill_to_index = {skill: i for i, skill in enumerate(skills)}\n",
    "        X = np.eye(len(skills))\n",
    "        distance = self.compute_distance(X, self.centroids)\n",
    "        clusters = self.find_closest_cluster(distance)\n",
    "        \n",
    "        # Assign each skill to a demand category based on the cluster\n",
    "        demand_levels = [\"low demand\", \"middle demand\", \"high demand\"]\n",
    "        skill_demand = {skill: demand_levels[cluster] for skill, cluster in zip(skills, clusters)}\n",
    "        return skill_demand\n",
    "\n",
    "skills = [\n",
    "    \"html\", \"css\", \"javascript\", \"react\", \"angular\", \"python\", \"data analysis\", \"machine learning\",\n",
    "    \"project management\", \"database\", \"sql\", \"nosql\", \"web development\", \"front-end\", \"back-end\"\n",
    "]\n",
    "\n",
    "kmeans = Kmeans(n_clusters=3)\n",
    "kmeans.fit(skills)\n",
    "skill_demand = kmeans.predict(skills)\n",
    "\n",
    "for skill, demand in skill_demand.items():\n",
    "    print(f\"Skill: {skill} {demand} level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills: social media platforms: ['low demand'] level \n",
      "Skills: content creation: ['low demand'] level \n",
      "Skills: and scheduling: ['low demand'] level \n",
      "Skills: social media: ['low demand'] level \n",
      "Skills: community engagement: ['low demand'] level \n",
      "Skills: paid social advertising: ['low demand'] level \n",
      "Skills: html: ['low demand'] level \n",
      "Skills: css: ['low demand'] level \n",
      "Skills: javascript: ['low demand'] level \n",
      "Skills: frontend frameworks: ['low demand'] level \n",
      "Skills: user experience ux: ['low demand'] level \n",
      "Skills: quality control processes and methodologies: ['low demand'] level \n",
      "Skills: statistical process control: ['low demand'] level \n",
      "Skills: spc root: ['low demand'] level \n",
      "Skills: cause analysis and corrective: ['low demand'] level \n",
      "Skills: quality management systems eg: ['low demand'] level \n",
      "Skills: regulatory knowledge: ['low demand'] level \n",
      "Skills: wireless network design: ['low demand'] level \n",
      "Skills: wifi standards and protocols: ['low demand'] level \n",
      "Skills: rf radio frequency: ['low demand'] level \n",
      "Skills: and optimization: ['low demand'] level \n",
      "Skills: wireless security protocols: ['low demand'] level \n",
      "Skills: troubleshooting: ['low demand'] level \n",
      "Skills: wireless network issues: ['low demand'] level \n",
      "Skills: event planning: ['low demand'] level \n",
      "Skills: conference logistics: ['low demand'] level \n",
      "Skills: budget management: ['low demand'] level \n",
      "Skills: vendor coordination: ['low demand'] level \n",
      "Skills: marketing and promotion: ['low demand'] level \n",
      "Skills: client relations: ['low demand', 'low demand'] level \n",
      "Skills: ui design: ['low demand'] level \n",
      "Skills: graphic design: ['low demand'] level \n",
      "Skills: adobe photoshop: ['low demand'] level \n",
      "Skills: typography and color theory: ['low demand'] level \n",
      "Skills: visual design and layout: ['low demand'] level \n",
      "Skills: responsive design: ['low demand'] level \n",
      "Skills: account management: ['low demand'] level \n",
      "Skills: marketing strategies: ['low demand'] level \n",
      "Skills: campaign optimization: ['low demand'] level \n",
      "Skills: data analysis: ['low demand'] level \n",
      "Skills: communication skills: ['low demand'] level \n",
      "Skills: product innovation: ['low demand'] level \n",
      "Skills: prototype development: ['low demand'] level \n",
      "Skills: test automation: ['low demand'] level \n",
      "Skills: test framework development: ['low demand'] level \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dell/.local/lib/python3.8/site-packages/numpy/core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class Kmeans:\n",
    "    '''Implementing Kmeans algorithm.'''\n",
    "\n",
    "    def __init__(self, n_clusters, max_iter=100, random_state=123):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def initializ_centroids(self, X):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        random_idx = rng.permutation(len(X))\n",
    "        centroids = X[random_idx[:self.n_clusters]]\n",
    "        return centroids\n",
    "\n",
    "\n",
    "\n",
    "    def compute_centroids(self, X, labels):\n",
    "        centroids = np.zeros((self.n_clusters, len(X[0])))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels == k, :], axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def compute_distance(self, X, centroids):\n",
    "        distance = np.zeros((len(X), self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroid_tile = np.tile(centroids[k, :], (len(X), 1)).T  # Transpose centroid_tile\n",
    "            row_norm = norm(X - centroid_tile, axis=1)\n",
    "            distance[:, k] = np.square(row_norm)\n",
    "        return distance\n",
    "\n",
    "\n",
    "\n",
    "    def find_closest_cluster(self, distance):\n",
    "        return np.argmin(distance, axis=1)\n",
    "\n",
    "    def compute_sse(self, X, labels, centroids):\n",
    "        distance = np.zeros(len(X))\n",
    "        for k in range(self.n_clusters):\n",
    "            distance[labels == k] = norm(X[labels == k] - centroids[k], axis=1)\n",
    "        return np.sum(np.square(distance))\n",
    "\n",
    "    def fit(self, skills):\n",
    "        flattened_skills = [skill for sublist in skills for skill in sublist]\n",
    "        skill_to_index = {skill: i for i, skill in enumerate(flattened_skills)}\n",
    "        X = np.eye(len(flattened_skills))\n",
    "        self.centroids = self.initializ_centroids(X)\n",
    "        for i in range(self.max_iter):\n",
    "            old_centroids = self.centroids\n",
    "            distance = self.compute_distance(X, old_centroids)\n",
    "            self.labels = self.find_closest_cluster(distance)\n",
    "            self.centroids = self.compute_centroids(X, self.labels)\n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "        self.error = self.compute_sse(X, self.labels, self.centroids)\n",
    "\n",
    "\n",
    "    def predict(self, skills):\n",
    "        flattened_skills = [skill for sublist in skills for skill in sublist]\n",
    "        X = np.eye(len(flattened_skills))\n",
    "        distance = self.compute_distance(X, self.centroids)\n",
    "        clusters = self.find_closest_cluster(distance)\n",
    "\n",
    "        # Assign each skill to a demand category based on the cluster\n",
    "        demand_levels = [\"low demand\", \"middle demand\", \"high demand\"]\n",
    "        skill_demand = {skill: [] for skill in flattened_skills}\n",
    "        for skill, cluster in zip(flattened_skills, clusters):\n",
    "            skill_demand[skill].append(demand_levels[cluster])\n",
    "        return skill_demand\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "skills = [\n",
    "      ['social media platforms', 'content creation', 'and scheduling', 'social media', 'community engagement', 'paid social advertising'],\n",
    "    ['html', 'css', 'javascript', 'frontend frameworks', 'user experience ux'],\n",
    "    ['quality control processes and methodologies', 'statistical process control', 'spc root', 'cause analysis and corrective', 'quality management systems eg', 'regulatory knowledge'],\n",
    "    ['wireless network design', 'wifi standards and protocols', 'rf radio frequency', 'and optimization', 'wireless security protocols', 'troubleshooting', 'wireless network issues'],\n",
    "    ['event planning', 'conference logistics', 'budget management', 'vendor coordination', 'marketing and promotion', 'client relations'],\n",
    "    ['ui design', 'graphic design', 'adobe photoshop', 'typography and color theory', 'visual design and layout', 'responsive design'],\n",
    "    ['account management', 'client relations', 'marketing strategies', 'campaign optimization', 'data analysis', 'communication skills'],\n",
    "    ['product innovation', 'prototype development'],\n",
    "    ['test automation', 'test framework development']\n",
    "]\n",
    "\n",
    "kmeans = Kmeans(n_clusters=3)\n",
    "kmeans.fit(skills)\n",
    "skill_demand = kmeans.predict(skills)\n",
    "\n",
    "for skill, demand in skill_demand.items():\n",
    "    print(f\"Skills: {skill}: {demand} level \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Skill: html : low demand\n",
      " Skill: css : low demand\n",
      " Skill: javascript : middle demand\n",
      " Skill: react : low demand\n",
      " Skill: angular : low demand\n",
      " Skill: python : low demand\n",
      " Skill: data analysis : low demand\n",
      " Skill: machine learning : low demand\n",
      " Skill: project management : low demand\n",
      " Skill: database : low demand\n",
      " Skill: sql : low demand\n",
      " Skill: nosql : low demand\n",
      " Skill: web development : low demand\n",
      " Skill: front-end : low demand\n",
      " Skill: back-end : high demand\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class Kmeans:\n",
    "    '''Implementing Kmeans algorithm.'''\n",
    "\n",
    "    def __init__(self, n_clusters, max_iter=100, random_state=123):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def initializ_centroids(self, X):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        random_idx = rng.permutation(len(X))\n",
    "        centroids = X[random_idx[:self.n_clusters]]\n",
    "        return centroids\n",
    "\n",
    "    def compute_centroids(self, X, labels):\n",
    "        centroids = np.zeros((self.n_clusters, len(X[0])))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels == k, :], axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def compute_distance(self, X, centroids):\n",
    "        distance = np.zeros((len(X), self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            row_norm = norm(X - centroids[k, :], axis=1)\n",
    "            distance[:, k] = np.square(row_norm)\n",
    "        return distance\n",
    "\n",
    "    def find_closest_cluster(self, distance):\n",
    "        return np.argmin(distance, axis=1)\n",
    "\n",
    "    def compute_sse(self, X, labels, centroids):\n",
    "        distance = np.zeros(len(X))\n",
    "        for k in range(self.n_clusters):\n",
    "            distance[labels == k] = norm(X[labels == k] - centroids[k], axis=1)\n",
    "        return np.sum(np.square(distance))\n",
    "\n",
    "    def fit(self, skills):\n",
    "        skill_to_index = {skill: i for i, skill in enumerate(skills)}\n",
    "        X = np.eye(len(skills))\n",
    "        self.centroids = self.initializ_centroids(X)\n",
    "        for i in range(self.max_iter):\n",
    "            old_centroids = self.centroids\n",
    "            distance = self.compute_distance(X, old_centroids)\n",
    "            self.labels = self.find_closest_cluster(distance)\n",
    "            self.centroids = self.compute_centroids(X, self.labels)\n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "        self.error = self.compute_sse(X, self.labels, self.centroids)\n",
    "\n",
    "    def predict(self, skills):\n",
    "        skill_to_index = {skill: i for i, skill in enumerate(skills)}\n",
    "        X = np.eye(len(skills))\n",
    "        distance = self.compute_distance(X, self.centroids)\n",
    "        clusters = self.find_closest_cluster(distance)\n",
    "        \n",
    "        # Assign each skill to a demand category based on the cluster\n",
    "        demand_levels = [\"low demand\", \"middle demand\", \"high demand\"]\n",
    "        skill_demand = {skill: demand_levels[cluster] for skill, cluster in zip(skills, clusters)}\n",
    "        return skill_demand\n",
    "\n",
    "skills = [\n",
    "    \"html\", \"css\", \"javascript\", \"react\", \"angular\", \"python\", \"data analysis\", \"machine learning\",\n",
    "    \"project management\", \"database\", \"sql\", \"nosql\", \"web development\", \"front-end\", \"back-end\"\n",
    "]\n",
    "\n",
    "kmeans = Kmeans(n_clusters=3)\n",
    "kmeans.fit(skills)\n",
    "skill_demand = kmeans.predict(skills)\n",
    "\n",
    "for skill, demand in skill_demand.items():\n",
    "    print(f\" Skill: {skill} : {demand}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Skill: social media platforms : low demand\n",
      " Skill: content creation : low demand\n",
      " Skill: and scheduling : low demand\n",
      " Skill: social media : low demand\n",
      " Skill: community engagement : low demand\n",
      " Skill: paid social advertising : low demand\n",
      " Skill: html : low demand\n",
      " Skill: css : low demand\n",
      " Skill: javascript : low demand\n",
      " Skill: frontend frameworks : low demand\n",
      " Skill: user experience ux : low demand\n",
      " Skill: quality control processes and methodologies : low demand\n",
      " Skill: statistical process control : low demand\n",
      " Skill: spc root : low demand\n",
      " Skill: cause analysis and corrective : low demand\n",
      " Skill: quality management systems eg : low demand\n",
      " Skill: regulatory knowledge : low demand\n",
      " Skill: wireless network design : low demand\n",
      " Skill: wifi standards and protocols : low demand\n",
      " Skill: rf radio frequency : low demand\n",
      " Skill: and optimization : low demand\n",
      " Skill: wireless security protocols : low demand\n",
      " Skill: troubleshooting : low demand\n",
      " Skill: wireless network issues : low demand\n",
      " Skill: event planning : low demand\n",
      " Skill: conference logistics : low demand\n",
      " Skill: budget management : low demand\n",
      " Skill: vendor coordination : low demand\n",
      " Skill: marketing and promotion : low demand\n",
      " Skill: client relations : low demand\n",
      " Skill: ui design : low demand\n",
      " Skill: graphic design : low demand\n",
      " Skill: adobe photoshop : low demand\n",
      " Skill: typography and color theory : low demand\n",
      " Skill: visual design and layout : low demand\n",
      " Skill: responsive design : low demand\n",
      " Skill: account management : low demand\n",
      " Skill: marketing strategies : low demand\n",
      " Skill: campaign optimization : low demand\n",
      " Skill: data analysis : low demand\n",
      " Skill: communication skills : low demand\n",
      " Skill: product innovation : low demand\n",
      " Skill: prototype development : low demand\n",
      " Skill: test automation : low demand\n",
      " Skill: test framework development : low demand\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class Kmeans:\n",
    "    '''Implementing Kmeans algorithm.'''\n",
    "\n",
    "    def __init__(self, n_clusters, max_iter=100, random_state=123):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def initializ_centroids(self, X):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        random_idx = rng.permutation(len(X))\n",
    "        centroids = X[random_idx[:self.n_clusters]]\n",
    "        return centroids\n",
    "\n",
    "    def compute_centroids(self, X, labels):\n",
    "        centroids = np.zeros((self.n_clusters, len(X[0])))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels == k, :], axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def compute_distance(self, X, centroids):\n",
    "        distance = np.zeros((len(X), self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            row_norm = norm(X - centroids[k, :], axis=1)\n",
    "            distance[:, k] = np.square(row_norm)\n",
    "        return distance\n",
    "\n",
    "    def find_closest_cluster(self, distance):\n",
    "        return np.argmin(distance, axis=1)\n",
    "\n",
    "    def compute_sse(self, X, labels, centroids):\n",
    "        distance = np.zeros(len(X))\n",
    "        for k in range(self.n_clusters):\n",
    "            distance[labels == k] = norm(X[labels == k] - centroids[k], axis=1)\n",
    "        return np.sum(np.square(distance))\n",
    "\n",
    "    def fit(self, skills):\n",
    "        flattened_skills = [item for sublist in skills for item in sublist]\n",
    "        skill_to_index = {skill: i for i, skill in enumerate(flattened_skills)}\n",
    "        X = np.eye(len(flattened_skills))\n",
    "        self.centroids = self.initializ_centroids(X)\n",
    "        for i in range(self.max_iter):\n",
    "            old_centroids = self.centroids\n",
    "            distance = self.compute_distance(X, old_centroids)\n",
    "            self.labels = self.find_closest_cluster(distance)\n",
    "            self.centroids = self.compute_centroids(X, self.labels)\n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "        self.error = self.compute_sse(X, self.labels, self.centroids)\n",
    "\n",
    "\n",
    "    def predict(self, skills):\n",
    "        flattened_skills = [item for sublist in skills for item in sublist]\n",
    "        X = np.eye(len(flattened_skills))\n",
    "        distance = self.compute_distance(X, self.centroids)\n",
    "        clusters = self.find_closest_cluster(distance)\n",
    "        \n",
    "        # Assign each skill to a demand category based on the cluster\n",
    "        demand_levels = [\"low demand\", \"middle demand\", \"high demand\"]\n",
    "        skill_demand = {}\n",
    "        for sublist, cluster in zip(skills, clusters):\n",
    "            for skill in sublist:\n",
    "                skill_demand[skill] = demand_levels[cluster]\n",
    "        return skill_demand\n",
    "\n",
    "\n",
    "\n",
    "skills = [\n",
    "    ['social media platforms', 'content creation', 'and scheduling', 'social media', 'community engagement', 'paid social advertising'],\n",
    "    ['html', 'css', 'javascript', 'frontend frameworks', 'user experience ux'],\n",
    "    ['quality control processes and methodologies', 'statistical process control', 'spc root', 'cause analysis and corrective', 'quality management systems eg', 'regulatory knowledge'],\n",
    "    ['wireless network design', 'wifi standards and protocols', 'rf radio frequency', 'and optimization', 'wireless security protocols', 'troubleshooting', 'wireless network issues'],\n",
    "    ['event planning', 'conference logistics', 'budget management', 'vendor coordination', 'marketing and promotion', 'client relations'],\n",
    "    ['ui design', 'graphic design', 'adobe photoshop', 'typography and color theory', 'visual design and layout', 'responsive design'],\n",
    "    ['account management', 'client relations', 'marketing strategies', 'campaign optimization', 'data analysis', 'communication skills'],\n",
    "    ['product innovation', 'prototype development'],\n",
    "    ['test automation', 'test framework development'],\n",
    "]\n",
    "\n",
    "kmeans = Kmeans(n_clusters=3)\n",
    "kmeans.fit(skills)\n",
    "skill_demand = kmeans.predict(skills)\n",
    "\n",
    "for skill, demand in skill_demand.items():\n",
    "    print(f\" Skill: {skill} : {demand}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "subtracting a sparse matrix from a nonzero scalar is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 106\u001b[0m\n\u001b[1;32m     93\u001b[0m skills \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     94\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial media platforms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent creation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand scheduling\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial media\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunity engagement\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaid social advertising\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     95\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjavascript\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrontend frameworks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser experience ux\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest automation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest framework development\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    103\u001b[0m ]\n\u001b[1;32m    105\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m Kmeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskills\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m skill_demand \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mpredict(skills)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m skill, demand \u001b[38;5;129;01min\u001b[39;00m skill_demand\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[124], line 64\u001b[0m, in \u001b[0;36mKmeans.fit\u001b[0;34m(self, skills)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[1;32m     63\u001b[0m     old_centroids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids\n\u001b[0;32m---> 64\u001b[0m     distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_centroids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_closest_cluster(distance)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_centroids(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels)\n",
      "Cell \u001b[0;32mIn[124], line 31\u001b[0m, in \u001b[0;36mKmeans.compute_distance\u001b[0;34m(self, X, centroids)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters):\n\u001b[1;32m     30\u001b[0m     centroid_broadcasted \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(centroids[k], (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 31\u001b[0m     row_norm \u001b[38;5;241m=\u001b[39m norm(\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcentroid_broadcasted\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m     distance[:, k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(row_norm)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distance\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_base.py:494\u001b[0m, in \u001b[0;36mspmatrix.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m isdense(other):\n\u001b[1;32m    493\u001b[0m     other \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_to(other, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sub_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_base.py:456\u001b[0m, in \u001b[0;36mspmatrix._sub_dense\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sub_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_base.py:502\u001b[0m, in \u001b[0;36mspmatrix.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubtracting a sparse matrix from a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    503\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonzero scalar is not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m isdense(other):\n\u001b[1;32m    505\u001b[0m     other \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_to(other, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: subtracting a sparse matrix from a nonzero scalar is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Kmeans:\n",
    "    '''Implementing Kmeans algorithm.'''\n",
    "\n",
    "    def __init__(self, n_clusters, max_iter=100, random_state=123):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def initializ_centroids(self, X):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        random_idx = rng.permutation(X.shape[0])\n",
    "        centroids = X[random_idx[:self.n_clusters]]\n",
    "        return centroids\n",
    "\n",
    "\n",
    "    def compute_centroids(self, X, labels):\n",
    "        centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels == k, :], axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def compute_distance(self, X, centroids):\n",
    "        distance = np.zeros((X.shape[0], self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroid_broadcasted = np.tile(centroids[k], (X.shape[0], 1))\n",
    "            row_norm = norm(X - centroid_broadcasted, axis=1)\n",
    "            distance[:, k] = np.square(row_norm)\n",
    "        return distance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def find_closest_cluster(self, distance):\n",
    "        return np.argmin(distance, axis=1)\n",
    "\n",
    "    def compute_sse(self, X, labels, centroids):\n",
    "        distance = np.zeros(len(X))\n",
    "        for k in range(self.n_clusters):\n",
    "            distance[labels == k] = norm(X[labels == k] - centroids[k], axis=1)\n",
    "        return np.sum(np.square(distance))\n",
    "\n",
    "    def fit(self, skills):\n",
    "        # Flatten the list of skills\n",
    "        flattened_skills = [skill for sublist in skills for skill in sublist]\n",
    "\n",
    "        # Feature extraction using TF-IDF\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(flattened_skills)\n",
    "        X = normalize(X)\n",
    "\n",
    "        # Initialize centroids\n",
    "        self.centroids = self.initializ_centroids(X)\n",
    "\n",
    "        # Perform KMeans clustering\n",
    "        for i in range(self.max_iter):\n",
    "            old_centroids = self.centroids\n",
    "            distance = self.compute_distance(X, old_centroids)\n",
    "            self.labels = self.find_closest_cluster(distance)\n",
    "            self.centroids = self.compute_centroids(X, self.labels)\n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "        self.error = self.compute_sse(X, self.labels, self.centroids)\n",
    "\n",
    "    def predict(self, skills):\n",
    "        # Flatten the list of skills\n",
    "        flattened_skills = [skill for sublist in skills for skill in sublist]\n",
    "\n",
    "        # Feature extraction using TF-IDF\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(flattened_skills)\n",
    "        X = normalize(X)\n",
    "\n",
    "        # Compute distance to centroids\n",
    "        distance = self.compute_distance(X, self.centroids)\n",
    "        clusters = self.find_closest_cluster(distance)\n",
    "\n",
    "        # Assign each skill to a demand category based on the cluster\n",
    "        demand_levels = [\"low demand\", \"middle demand\", \"high demand\"]\n",
    "        skill_demand = {}\n",
    "        for sublist, cluster in zip(skills, clusters):\n",
    "            for skill in sublist:\n",
    "                skill_demand[skill] = demand_levels[cluster]\n",
    "        return skill_demand\n",
    "\n",
    "\n",
    "skills = [\n",
    "    ['social media platforms', 'content creation', 'and scheduling', 'social media', 'community engagement', 'paid social advertising'],\n",
    "    ['html', 'css', 'javascript', 'frontend frameworks', 'user experience ux'],\n",
    "    ['quality control processes and methodologies', 'statistical process control', 'spc root', 'cause analysis and corrective', 'quality management systems eg', 'regulatory knowledge'],\n",
    "    ['wireless network design', 'wifi standards and protocols', 'rf radio frequency', 'and optimization', 'wireless security protocols', 'troubleshooting', 'wireless network issues'],\n",
    "    ['event planning', 'conference logistics', 'budget management', 'vendor coordination', 'marketing and promotion', 'client relations'],\n",
    "    ['ui design', 'graphic design', 'adobe photoshop', 'typography and color theory', 'visual design and layout', 'responsive design'],\n",
    "    ['account management', 'client relations', 'marketing strategies', 'campaign optimization', 'data analysis', 'communication skills'],\n",
    "    ['product innovation', 'prototype development'],\n",
    "    ['test automation', 'test framework development'],\n",
    "]\n",
    "\n",
    "kmeans = Kmeans(n_clusters=3)\n",
    "kmeans.fit(skills)\n",
    "skill_demand = kmeans.predict(skills)\n",
    "\n",
    "for skill, demand in skill_demand.items():\n",
    "    print(f\" Skill: {skill} : {demand}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
